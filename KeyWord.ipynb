{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8541a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keybert\n",
    "# pip install kex\n",
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea18dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jennifer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2023-12-05 14:37:57 INFO     Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2023-12-05 14:37:57 INFO     Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "import kex\n",
    "import pandas as pd\n",
    "from segtok.segmenter import split_multi\n",
    "from segtok.tokenizer import web_tokenizer, split_contractions\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "__stemmer = PorterStemmer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from _stopwords import get_stopwords_list\n",
    "from itertools import chain\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "  \n",
    "#nlp =spacy.load('en_core_web_sm')\n",
    "kw_model = KeyBERT()\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9144e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "BCpolitics = pd.read_csv(\"aws/BCpolitics1.csv\")\n",
    "CanadianPolitics = pd.read_csv(\"aws/CanadianPolitics.csv\")\n",
    "vancouver = pd.read_csv(\"vancouver.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd70668",
   "metadata": {},
   "source": [
    "## housing affordability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e4417ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_list= [\"Affordable housing\",\"Affordable living\",\"Reasonable housing\",\"Inexpensive housing\",\"Low-cost housing\"\n",
    "             ,\"Economical housing\",\"Attainable housing\"]\n",
    "house_list = list(map(lambda x: __stemmer.stem(x), house_list)) \n",
    "house_list = list(dict.fromkeys(house_list))\n",
    "def sim_score(keyword_list, topic): \n",
    "    scores = []\n",
    "    for keyword in keyword_list:\n",
    "        \n",
    "        if keyword is not None:\n",
    "            for i in keyword:\n",
    "                key = __stemmer.stem(i[0])\n",
    "                if key in topic:\n",
    "                    score = 1\n",
    "                else:\n",
    "                    score =0\n",
    "        else:\n",
    "            score= 0\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7443329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_kex_list(text):\n",
    "    ans = []\n",
    "    keys_stemmed = [k['stemmed'] for k in text]\n",
    "    ans.append(keys_stemmed)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e7b11e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_keybert_list(text):\n",
    "    ans = []\n",
    "    keys = []\n",
    "    for j in range(len(text)):\n",
    "        keys.append(text[j][0])\n",
    "    keys_stemmed = list(map(lambda x: __stemmer.stem(x), keys)) \n",
    "    keys_stemmed = list(dict.fromkeys(keys_stemmed))\n",
    "    ans.append(keys_stemmed)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03c73452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword(df, model_name):\n",
    "    if(model_name == \"keybert\"):\n",
    "        df[\"keyword\"] = df[\"title\"].apply(lambda x: kw_model.extract_keywords(x, keyphrase_ngram_range=(1,2), stop_words='english',\n",
    "                          use_mmr=True, diversity=0.7)if not pd.isnull(x)else None)\n",
    "        df[\"keyword\"] =df[\"keyword\"].apply(lambda x: append_keybert_list(x)if not x is None else None)\n",
    "    elif(model_name == \"TopicRank\"):\n",
    "        model = kex.TopicRank()\n",
    "        df[\"keyword\"] =df[\"title\"].apply(lambda x: model.get_keywords(x)if not pd.isnull(x)else None)\n",
    "        df[\"keyword\"] =df[\"keyword\"].apply(lambda x: append_kex_list(x)if not x is None else None)\n",
    "    elif(model_name == \"TFIDF\"):\n",
    "        model = kex.TFIDF()\n",
    "        model.train(df[\"title\"][0], export_directory='./tmp')\n",
    "        df[\"keyword\"] =df[\"title\"].apply(lambda x: model.get_keywords(x, n_keywords=1000)if not pd.isnull(x)else None)\n",
    "        df[\"keyword\"] =df[\"keyword\"].apply(lambda x: append_kex_list(x)if not x is None else None)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
